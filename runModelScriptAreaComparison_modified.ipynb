{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "runModelScriptAreaComparison_modified.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindyhfls/NMA_DL_2021_project/blob/main/runModelScriptAreaComparison_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvAi0U0g3Ex8",
        "outputId": "aadf8dd1-df2f-41f9-e36c-b4f2268f5a54"
      },
      "source": [
        "#@title Import matplotlib, class functions, and set up variables.\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True\n",
        "# Data Loading\n",
        "\n",
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))\n",
        "\n",
        "#@title Print Keys\n",
        "print(alldat[0].keys())\n",
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "#@title Define Steinmetz Class\n",
        "class SteinmetzSession:\n",
        "  data = []\n",
        "  binSize = 10\n",
        "  nTrials = []\n",
        "  nNeurons = []\n",
        "  trialLen = 0\n",
        "  trimStart = \"trialStart\"\n",
        "  trimEnd =  \"trialEnd\"\n",
        "  def __init__(self, dataIn):\n",
        "    self.data = copy.deepcopy(dataIn)\n",
        "    dims1 = np.shape(dataIn['spks'])\n",
        "    self.nTrials = dims1[1]\n",
        "    self.nNeurons = dims1[0]\n",
        "    self.trialLen = dims1[2]\n",
        "\n",
        "  def binData(self, binSizeIn): # Inputs: data, scalar for binning. Combines binSizeIn bins together to bin data smaller Ex. binSizeIn of 5 on the original dataset combines every 5 10 ms bins into one 50 ms bin across all trials.\n",
        "    varsToRebinSum = ['spks']\n",
        "    varsToRebinMean = ['wheel', 'pupil']\n",
        "    spikes = self.data['spks']\n",
        "    histVec = range(0,self.trialLen+1, binSizeIn)\n",
        "    spikesBin = np.zeros((self.nNeurons, self.nTrials, len(histVec)))\n",
        "    print(histVec)\n",
        "    for trial in range(self.nTrials):\n",
        "      spikes1 = np.squeeze(spikes[:,trial,:])\n",
        "      for time1 in range(len(histVec)-1):\n",
        "        spikesBin[:,trial, time1] = np.sum(spikes1[:, histVec[time1]:histVec[time1+1]-1], axis=1)\n",
        "\n",
        "    spikesBin = spikesBin[:,:,:-1]\n",
        "    self.data['spks'] = spikesBin\n",
        "    self.trialLen = len(histVec) -1\n",
        "    self.binSize = self.binSize*binSizeIn\n",
        "\n",
        "    \n",
        "    s = \"Binned spikes, turning a \" + repr(np.shape(spikes)) + \" matrix into a \" + repr(np.shape(spikesBin)) + \" matrix\"\n",
        "    print(s)\n",
        "\n",
        "  def plotTrial(self, trialNum): # Basic function to plot the firing rate during a single trial. Used for debugging trimming and binning\n",
        "    plt.imshow(np.squeeze(self.data['spks'][:,trialNum,:]), cmap='gray_r', aspect = 'auto')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"Time (bins)\")\n",
        "    plt.ylabel(\"Neuron #\")\n",
        "    \n",
        "  def realign_data_to_movement(self,length_time_in_ms): # input has to be n * nTrials * nbins\n",
        "    align_time_in_bins = np.round(self.data['response_time']/self.binSize*1000)+ int(500/self.binSize) # has to add 0.5 s because the first 0.5 s is pre-stimulus\n",
        "    length_time_in_bins = int(length_time_in_ms/self.binSize)\n",
        "    validtrials = self.data['response']!=0\n",
        "    maxtime = self.trialLen\n",
        "    newshape = (self.nNeurons,self.nTrials)\n",
        "    newshape+=(length_time_in_bins,)\n",
        "    newdata = np.empty(newshape)\n",
        "    for count,align_time_curr_trial in enumerate(align_time_in_bins):\n",
        "      if (validtrials[count]==0)|(align_time_curr_trial+length_time_in_bins>maxtime) :\n",
        "        validtrials[count] = 0\n",
        "      else:\n",
        "        newdata[:,count,:]= self.data['spks'][:,count,int(align_time_curr_trial):int(align_time_curr_trial)+length_time_in_bins]\n",
        "    # newdata = newdata[:,validtrials,:]\n",
        "    self.data['spks'] = newdata\n",
        "    # self.validtrials = validtrials\n",
        "    print('spikes aligned to movement, returning validtrials')\n",
        "    return validtrials\n",
        "  \n",
        "  def get_areas(self):\n",
        "    print(set(list(self.data['brain_area'])))\n",
        "\n",
        "  def extractROI(self, region): #### extract neurons from single region\n",
        "    rmrt=list(np.where(self.data['brain_area']!=region))[0]\n",
        "    print(f' removing data from {len(rmrt)} neurons not contained in {region} ')\n",
        "    self.data['spks']=np.delete(self.data['spks'],rmrt,axis=0)\n",
        "    neur=len(self.data['spks'])\n",
        "    print(f'neurons remaining in trial {neur}')\n",
        "    self.data['brain_area']=np.delete(self.data['brain_area'],rmrt,axis=0)\n",
        "    self.data['ccf']=np.delete(self.data['ccf'],rmrt,axis=0)\n",
        "    \n",
        "  def FlattenTs(self):\n",
        "    self.data['spks']=np.hstack(self.data['spks'][:])\n",
        "\n",
        "  def removeTrialAvgFR(self):\n",
        "    mFR = self.data['spks'].mean(1)\n",
        "    mFR = np.expand_dims(mFR, 1)\n",
        "    print(np.shape(self.data['spks']))\n",
        "    print(np.shape(mFR))\n",
        "    self.data['spks'] = self.data['spks'].astype(float)\n",
        "    self.data['spks'] -= mFR\n",
        "\n",
        "  def sqrt_norm(self):\n",
        "    self.data['spks'] = np.sqrt(self.data['spks'])  \n",
        "  \n",
        "  def permdims(self):\n",
        "    return torch.permute(torch.tensor(self.data['spks']),(2,1,0))\n",
        "\n",
        "  def smoothFR(self, smoothingWidth):# TODO: Smooth the data and save it back to the data structure\n",
        "    return 0\n",
        "\n",
        "#@title get input for network from session 31\n",
        "s31=SteinmetzSession(alldat[30])\n",
        "s31.sqrt_norm()\n",
        "s31.removeTrialAvgFR()\n",
        "validtrials = s31.realign_data_to_movement(500) # get 500 ms from movement time, \n",
        "# cannot get realign and binning to work the same time =[\n",
        "\n",
        "# Model\n",
        "class Net(nn.Module): # our model\n",
        "  def __init__(self, ncomp, NN1, NN2, bidi=True, dropout = 0):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # play with some of the options in the RNN!\n",
        "    self.rnn1 = nn.RNN(NN1, ncomp, num_layers = 1, dropout = 0, # MO\n",
        "                      bidirectional = bidi, nonlinearity = 'tanh')\n",
        "    self.rnn2 = nn.RNN(NN2,ncomp,num_layers = 1, dropout = 0, bidirectional = bidi, nonlinearity = 'tanh') #TH\n",
        "\n",
        "    if bidi == True:\n",
        "      self.fclatent = nn.Linear(ncomp*2,ncomp*2)\n",
        "    else: \n",
        "      self.fclatent = nn.Linear(ncomp,ncomp)\n",
        "\n",
        "    self.fc = nn.Linear(ncomp,NN1)\n",
        "\n",
        "  def forward(self, x0,x1):\n",
        "    y2 = self.rnn2(x0)[0] # ncomp TH\n",
        "    y =  self.rnn1(x1)[0] # ncomp MOs\n",
        "    y = y + self.fclatent(y2) # ncomp MOs with projection of latent TH components\n",
        "\n",
        "    if self.rnn1.bidirectional:\n",
        "      # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
        "      # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
        "      q = (y[:, :, :ncomp] + y[:, :, ncomp:])/2\n",
        "    else:\n",
        "      q = y\n",
        "\n",
        "    # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
        "    # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
        "    z = F.softplus(self.fc(q), 10)\n",
        "\n",
        "    return z, q\n",
        "\n",
        "def pearson_corr_tensor(input, output):\n",
        "  rpred = output.detach().cpu().numpy()\n",
        "  rreal = input.detach().cpu().numpy()\n",
        "  rpred_flat = np.ndarray.flatten(rpred)\n",
        "  rreal_flat = np.ndarray.flatten(rreal)\n",
        "  corrcoeff = np.corrcoef(rpred_flat, rreal_flat)\n",
        "  return corrcoeff[0,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['spks', 'wheel', 'pupil', 'response', 'response_time', 'bin_size', 'stim_onset', 'contrast_right', 'contrast_left', 'brain_area', 'feedback_time', 'feedback_type', 'gocue', 'mouse_name', 'date_exp', 'trough_to_peak', 'active_trials', 'contrast_left_passive', 'contrast_right_passive', 'spks_passive', 'pupil_passive', 'wheel_passive', 'prev_reward', 'ccf', 'ccf_axes', 'cellid_orig', 'reaction_time', 'face', 'face_passive', 'licks', 'licks_passive'])\n",
            "(977, 237, 250)\n",
            "(977, 1, 250)\n",
            "spikes aligned to movement, returning validtrials\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7qYqmU53Vua"
      },
      "source": [
        "def runAreaModels(s31, lr, firstArea, secondArea, latentSize, nIter, validtrials, dropout, bidi, plotExamples = False, verboseFlag = False):\n",
        "  ### print areas\n",
        "  s31.get_areas()\n",
        "\n",
        "  # s31.FlattenTs()\n",
        "  nTr = np.argwhere(validtrials) # since the other trials were defaulted to a zero value, only plot the valid trials\n",
        "\n",
        "  MO = copy.deepcopy(s31)\n",
        "  ###remove all neurons not in motor cortex\n",
        "  MO.extractROI(firstArea)\n",
        "\n",
        "  ### plot a trial from motor neuron\n",
        "  if plotExamples:\n",
        "    plt.figure()\n",
        "    MO.plotTrial(nTr[1])\n",
        "    plt.title(firstArea)\n",
        "\n",
        "  ### permute the trials\n",
        "  MOdata = MO.permdims().float().to(device)\n",
        "  MOdata = MOdata[:,validtrials,:]\n",
        "  print(MOdata.shape)\n",
        "\n",
        "  TH = copy.deepcopy(s31)\n",
        "  ###remove all neurons not in motor cortex\n",
        "  TH.extractROI(secondArea)\n",
        "  ### plot a trial from motor neuron\n",
        "  if plotExamples:\n",
        "    plt.figure()\n",
        "    TH.plotTrial(nTr[1])\n",
        "    plt.title(secondArea)\n",
        "\n",
        "  THdata = TH.permdims().float().to(device)\n",
        "  THdata = THdata[:,validtrials,:]\n",
        "\n",
        "  NN1 = MOdata.shape[2]\n",
        "  NN2 = THdata.shape[2]\n",
        "\n",
        "  N = MOdata.shape[1]\n",
        "  np.random.seed(42)\n",
        "  ii = torch.randperm(N).tolist()\n",
        "  idx_train = ii[:math.floor(0.6*N)]\n",
        "  idx_val = ii[math.floor(0.6*N):math.floor(0.9*N)]\n",
        "  idx_test = ii[math.floor(0.9*N):]\n",
        "\n",
        "  x0_train = THdata[:,idx_train,:]\n",
        "  x0_val = THdata[:,idx_val,:]\n",
        "  x0_test = THdata[:,idx_test,:]\n",
        "\n",
        "  x1_train = MOdata[:,idx_train,:]\n",
        "  x1_val = MOdata[:,idx_val,:]\n",
        "  x1_test = MOdata[:,idx_test,:]\n",
        "  ncomp = latentSize\n",
        "\n",
        "  learning_rate_start = lr\n",
        "  net_baseline = Net(ncomp, NN1, NN2, bidi = bidi, dropout= dropout).to(device)\n",
        "  net_baseline.fclatent.weight.data[:] = 0 # fixed weights =0 so the TH input is not considered\n",
        "  net_baseline.fclatent.bias.data[:] = 0\n",
        "  net_baseline.fclatent.weight.requires_grad = False\n",
        "  net_baseline.fclatent.bias.requires_grad = False\n",
        "\n",
        "  # special thing:  we initialize the biases of the last layer in the neural network\n",
        "  # we set them as the mean firing rates of the neurons.\n",
        "  # this should make the initial predictions close to the mean, because the latents don't contribute much\n",
        "  # net_baseline.fc.bias.data[:] = MOdata.mean((0,1))\n",
        "\n",
        "  # we set up the optimizer later in the training loop\n",
        "  if verboseFlag:\n",
        "    print(net_baseline)\n",
        "\n",
        "  loss = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(net_baseline.parameters(), lr=learning_rate_start)\n",
        "\n",
        "  training_cost = []\n",
        "  val_cost = []\n",
        "  for k in range(nIter):\n",
        "    ### training\n",
        "    optimizer.zero_grad()\n",
        "    # the network outputs the single-neuron prediction and the latents\n",
        "    z, y = net_baseline(x0_train,x1_train)\n",
        "    cost = loss(z,x1_train).mean()\n",
        "    # # our log-likelihood cost\n",
        "    # cost = Poisson_loss(z, x1_train).mean()\n",
        "    # train the network as usual\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    training_cost.append(cost.item())\n",
        "\n",
        "    ### test on validation data\n",
        "    z_val,_ = net_baseline(x0_val,x1_val)\n",
        "    cost = loss(z_val,x1_val).mean()\n",
        "    # cost = Poisson_loss(z_val, x1_val).mean()\n",
        "    val_cost.append(cost.item())\n",
        "\n",
        "    if k % 100 == 0:\n",
        "      if verboseFlag:\n",
        "        print(f'iteration {k}, cost {cost.item():.4f}')\n",
        "\n",
        "  if plotExamples:\n",
        "    plt.plot(training_cost,'b')\n",
        "    plt.plot(val_cost,'r')\n",
        "    plt.hlines(np.min(training_cost),0,nIter,'b',linestyles = '--')\n",
        "    plt.hlines(np.min(val_cost),0,nIter,'r',linestyles = '--')\n",
        "\n",
        "    plt.legend(['training cost','validation cost','min training cost','min validation cost'])\n",
        "    plt.title('Training cost over epochs')\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('epochs')\n",
        "\n",
        "  corr = pearson_corr_tensor(x1_val, z_val)\n",
        "\n",
        "  rpred = z.detach().cpu().numpy()\n",
        "  rates = x1_train.cpu()\n",
        "\n",
        "  if plotExamples:\n",
        "    nTr = 5\n",
        "    nNeuron = 0\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(rates[:,nTr, nNeuron])\n",
        "    plt.plot(rpred[:,nTr, nNeuron])\n",
        "\n",
        "    plt.legend(['spikes', 'rates (predicted)'])\n",
        "    plt.title(f'training set Trial {nTr}, Neuron {nNeuron}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize = (12, 8))\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(rates[:, nTr, :].T, cmap='gray_r')\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Cell #')\n",
        "    plt.title(f'True rates (training set trial {nTr})')\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(rpred[:, nTr, :].T, cmap='gray_r')\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Cell #')\n",
        "    plt.title(f'Inferred rates (training set trial {nTr})')\n",
        "    plt.show()\n",
        "\n",
        "  PATH = 'steinmetz_model_baseline.pt'\n",
        "  torch.save(net_baseline.state_dict(), PATH) \n",
        "  del net_baseline\n",
        "\n",
        "  # load saved model\n",
        "  net_baseline = Net(ncomp, NN1, NN2, bidi = bidi, dropout= dropout).to(device)\n",
        "  net_baseline.load_state_dict(torch.load('steinmetz_model_baseline.pt'))\n",
        "\n",
        "  # after training the baseline network, get the weights of rnn1 and freeze it\n",
        "  net_withinput  = copy.deepcopy(net_baseline)\n",
        "\n",
        "  net_withinput.fclatent.weight.requires_grad = True\n",
        "  net_withinput.fclatent.bias.requires_grad = True\n",
        "\n",
        "  # # set weight initalization to random\n",
        "  net_withinput.fclatent.reset_parameters()\n",
        "\n",
        "\n",
        "  net_withinput.rnn1.weight_ih_l0.requires_grad = False\n",
        "  net_withinput.rnn1.weight_hh_l0.requires_grad = False\n",
        "  net_withinput.rnn1.bias_ih_l0.requires_grad = False\n",
        "  net_withinput.rnn1.bias_hh_l0.requires_grad = False\n",
        "  if bidi:\n",
        "    net_withinput.rnn1.weight_ih_l0_reverse.requires_grad = False\n",
        "    net_withinput.rnn1.weight_hh_l0_reverse.requires_grad = False\n",
        "    net_withinput.rnn1.bias_ih_l0_reverse.requires_grad = False\n",
        "    net_withinput.rnn1.bias_hh_l0_reverse.requires_grad = False\n",
        "  \n",
        "  if verboseFlag:\n",
        "    print(net_withinput)\n",
        "\n",
        "\n",
        "  # we define the Poisson log-likelihood loss\n",
        "  # def Poisson_loss(lam, spk):\n",
        "  #   return lam - spk * torch.log(lam)\n",
        "  loss = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(net_withinput.parameters(), lr=learning_rate_start) # this is very important\n",
        "\n",
        "\n",
        "\n",
        "  training_cost2 = []\n",
        "  val_cost2 = []\n",
        "  for k in range(nIter):\n",
        "    ### training\n",
        "    optimizer.zero_grad()\n",
        "    # the network outputs the single-neuron prediction and the latents\n",
        "    z, y = net_withinput(x0_train,x1_train)\n",
        "    # our log-likelihood cost\n",
        "    cost = loss(z, x1_train).mean()\n",
        "    # train the network as usual\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    training_cost2.append(cost.item())\n",
        "\n",
        "    ### test on validation data\n",
        "    z_val,_ = net_withinput(x0_val,x1_val)\n",
        "    cost = loss(z_val, x1_val).mean()\n",
        "    val_cost2.append(cost.item())\n",
        "    if k % 100 == 0:\n",
        "      if verboseFlag:\n",
        "        print(f'iteration {k}, cost {cost.item():.4f}')\n",
        "\n",
        "  corr2 = pearson_corr_tensor(x1_val, z_val)\n",
        "\n",
        "  return training_cost, training_cost2, val_cost, val_cost2, corr, corr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIthuHsW3VrX",
        "outputId": "0ec7efc3-e607-423a-b847-ce495bf8e276"
      },
      "source": [
        "numSplits = 2\n",
        "doVec = np.linspace(0, 0.9, numSplits)\n",
        "bootstraps = 10\n",
        "nIter = 1000\n",
        "train_cost = np.zeros((numSplits, nIter, bootstraps))\n",
        "train_cost2 = np.zeros((numSplits, nIter, bootstraps))\n",
        "val_cost = np.zeros((numSplits, nIter, bootstraps))\n",
        "val_cost2 = np.zeros((numSplits, nIter, bootstraps))\n",
        "corr = np.zeros((numSplits, nIter, bootstraps))\n",
        "corr2 = np.zeros((numSplits, nIter, bootstraps))\n",
        "\n",
        "firstArea = 'MOs'\n",
        "secondArea = 'TH'\n",
        "thirdArea = 'OLF'\n",
        "\n",
        "latentSize = 3\n",
        "nIter = 1000\n",
        "dropout = .5\n",
        "bidi = False\n",
        "lr = 0.002\n",
        "\n",
        "\n",
        "for boot in range(bootstraps):\n",
        "  print(f'Bootstrap num ',{boot}, ' of ', {bootstraps})\n",
        "  train_cost[0,:, boot], train_cost2[0,:, boot], val_cost[0,:, boot], val_cost2[0,:, boot], corr[0,:, boot], corr2[0,:, boot] = runAreaModels(s31, lr, firstArea, secondArea, latentSize, nIter, validtrials, dropout, bidi, verboseFlag = False)\n",
        "  train_cost[1,:, boot], train_cost2[1,:, boot], val_cost[1,:, boot], val_cost2[1,:, boot], corr[1,:, boot], corr2[1,:, boot] = runAreaModels(s31, lr, firstArea, thirdArea, latentSize, nIter, validtrials, dropout, bidi, verboseFlag = False)\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(val_cost-1)\n",
        "# plt.plot(val_cost2-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bootstrap num  {0}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:924.)\n",
            "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {1}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {2}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {3}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {4}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {5}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {6}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {7}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {8}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n",
            "Bootstrap num  {9}  of  {10}\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 868 neurons not contained in TH \n",
            "neurons remaining in trial 109\n",
            "{'ORB', 'OLF', 'TH', 'SCm', 'MOs', 'CA3', 'POST', 'SNr'}\n",
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n",
            "torch.Size([50, 158, 281])\n",
            " removing data from 899 neurons not contained in OLF \n",
            "neurons remaining in trial 78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-96036a290026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cost\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cost2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             raise ValueError(f\"x and y can be no greater than 2-D, but have \"\n\u001b[0m\u001b[1;32m    346\u001b[0m                              f\"shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (2,) and (2, 1000, 10)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "kvcrA8KXA2k4",
        "outputId": "4c4e0255-f76a-41dc-b8e2-eb6342cab133"
      },
      "source": [
        "val_cost = val_cost.reshape(-1,)\n",
        "val_cost2 = val_cost2.reshape(-1,)\n",
        "print(np.shape(val_cost))\n",
        "print(np.shape(val_cost2))\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(val_cost)\n",
        "plt.plot(val_cost2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000,)\n",
            "(20000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efdd0982490>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}