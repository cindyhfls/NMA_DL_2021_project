{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Actual data",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindyhfls/NMA_DL_2021_project/blob/main/DifferentRegionsCorrelatedLatents/LoopTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ft3xlnUcqztQ"
      },
      "source": [
        "# Focus on what matters: inferring low-dimensional dynamics from neural recordings\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Marius Pachitariu, Pedram Mouseli, Lucas Tavares, Jonny Coutinho, \n",
        "Blessing Itoro, Gaurang Mahajan, Rishika Mohanta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Nty89M3rqztR"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "0az6GUU-qztR"
      },
      "source": [
        "---\n",
        "# Objective: \n",
        "It is very difficult to interpret the activity of single neurons in the brain, because their firing patterns are noisy, and it is not clear how a single neuron can contribute to cognition and behavior. However, neurons in the brain participate in local, regional and brainwide dynamics. No neuron is isolated from these dynamics, and much of a single neuron's activity can be predicted from the dynamics. Furthermore, only populations of neurons as a whole can control cognition and behavior. Hence it is crucial to identify these dynamical patterns and relate them to stimuli or behaviors. \n",
        "\n",
        "In this notebook, we generate simulated data from a low-dimensional dynamical system and then use seq-to-seq methods to predict one subset of neurons from another. This allows us to identify the low-dimensional dynamics that are sufficient to explain the activity of neurons in the simulation. The methods described in this notebook can be applied to large-scale neural recordings of hundreds to tens of thousans of neurons, such as the ones from the NMA-CN course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "_p-iXCfQqztR"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "4cAt7dwxqztR"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "import copy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "o5n0YugfqztS"
      },
      "source": [
        "# @title Figure settings\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Mrm1eJeSqztS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061121cf-3128-4bba-8854-476050a1134e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOItLRnP1Wjj"
      },
      "source": [
        "def pearson_corr_tensor(input, output):\n",
        "  rpred = output.detach().cpu().numpy()\n",
        "  rreal = input.detach().cpu().numpy()\n",
        "  rpred_flat = np.ndarray.flatten(rpred)\n",
        "  rreal_flat = np.ndarray.flatten(rreal)\n",
        "  corrcoeff = np.corrcoef(rpred_flat, rreal_flat)\n",
        "  return corrcoeff[0,1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38_VBFd2UKH-"
      },
      "source": [
        "#@title Set random seed\n",
        "\n",
        "#@markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "htA48tcWqztS"
      },
      "source": [
        "**Note:** If `cuda` is not enabled, go to `Runtime`--> `Change runtime type` and in `Hardware acceleration` choose `GPU`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWiCcZ2Xz44h"
      },
      "source": [
        "# Data Loading\n",
        "\n",
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP4xE0-30qRG",
        "outputId": "bf5c4c45-ced8-4c65-8ec3-5f6b5c15b9d4"
      },
      "source": [
        "#@title Print Keys\n",
        "print(alldat[0].keys())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['spks', 'wheel', 'pupil', 'response', 'response_time', 'bin_size', 'stim_onset', 'contrast_right', 'contrast_left', 'brain_area', 'feedback_time', 'feedback_type', 'gocue', 'mouse_name', 'date_exp', 'trough_to_peak', 'active_trials', 'contrast_left_passive', 'contrast_right_passive', 'spks_passive', 'pupil_passive', 'wheel_passive', 'prev_reward', 'ccf', 'ccf_axes', 'cellid_orig', 'reaction_time', 'face', 'face_passive', 'licks', 'licks_passive'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyNZF8eu2GJa"
      },
      "source": [
        "#@title Define Steinmetz Class\n",
        "class SteinmetzSession:\n",
        "  data = []\n",
        "  binSize = 10\n",
        "  nTrials = []\n",
        "  nNeurons = []\n",
        "  trialLen = 0\n",
        "  trimStart = \"trialStart\"\n",
        "  trimEnd =  \"trialEnd\"\n",
        "  def __init__(self, dataIn):\n",
        "    self.data = copy.deepcopy(dataIn)\n",
        "    dims1 = np.shape(dataIn['spks'])\n",
        "    self.nTrials = dims1[1]\n",
        "    self.nNeurons = dims1[0]\n",
        "    self.trialLen = dims1[2]\n",
        "\n",
        "  def binData(self, binSizeIn): # Inputs: data, scalar for binning. Combines binSizeIn bins together to bin data smaller Ex. binSizeIn of 5 on the original dataset combines every 5 10 ms bins into one 50 ms bin across all trials.\n",
        "    varsToRebinSum = ['spks']\n",
        "    varsToRebinMean = ['wheel', 'pupil']\n",
        "    spikes = self.data['spks']\n",
        "    histVec = range(0,self.trialLen+1, binSizeIn)\n",
        "    spikesBin = np.zeros((self.nNeurons, self.nTrials, len(histVec)))\n",
        "    print(histVec)\n",
        "    for trial in range(self.nTrials):\n",
        "      spikes1 = np.squeeze(spikes[:,trial,:])\n",
        "      for time1 in range(len(histVec)-1):\n",
        "        spikesBin[:,trial, time1] = np.sum(spikes1[:, histVec[time1]:histVec[time1+1]-1], axis=1)\n",
        "\n",
        "    spikesBin = spikesBin[:,:,:-1]\n",
        "    self.data['spks'] = spikesBin\n",
        "    self.trialLen = len(histVec) -1\n",
        "    self.binSize = self.binSize*binSizeIn\n",
        "\n",
        "    \n",
        "    s = \"Binned spikes, turning a \" + repr(np.shape(spikes)) + \" matrix into a \" + repr(np.shape(spikesBin)) + \" matrix\"\n",
        "    print(s)\n",
        "\n",
        "  def plotTrial(self, trialNum): # Basic function to plot the firing rate during a single trial. Used for debugging trimming and binning\n",
        "    plt.imshow(np.squeeze(self.data['spks'][:,trialNum,:]), cmap='gray_r', aspect = 'auto')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"Time (bins)\")\n",
        "    plt.ylabel(\"Neuron #\")\n",
        "    \n",
        "  def realign_data_to_movement(self,length_time_in_ms): # input has to be n * nTrials * nbins\n",
        "    align_time_in_bins = np.round(self.data['response_time']/self.binSize*1000)+ int(500/self.binSize) # has to add 0.5 s because the first 0.5 s is pre-stimulus\n",
        "    length_time_in_bins = int(length_time_in_ms/self.binSize)\n",
        "    validtrials = self.data['response']!=0\n",
        "    maxtime = self.trialLen\n",
        "    newshape = (self.nNeurons,self.nTrials)\n",
        "    newshape+=(length_time_in_bins,)\n",
        "    newdata = np.empty(newshape)\n",
        "    for count,align_time_curr_trial in enumerate(align_time_in_bins):\n",
        "      if (validtrials[count]==0)|(align_time_curr_trial+length_time_in_bins>maxtime) :\n",
        "        validtrials[count] = 0\n",
        "      else:\n",
        "        newdata[:,count,:]= self.data['spks'][:,count,int(align_time_curr_trial):int(align_time_curr_trial)+length_time_in_bins]\n",
        "    # newdata = newdata[:,validtrials,:]\n",
        "    self.data['spks'] = newdata\n",
        "    # self.validtrials = validtrials\n",
        "    print('spikes aligned to movement, returning validtrials')\n",
        "    return validtrials\n",
        "  \n",
        "  def get_areas(self):\n",
        "    print(set(list(self.data['brain_area'])))\n",
        "    return set(list(self.data['brain_area']))\n",
        "\n",
        "  def extractROI(self, region): #### extract neurons from single region\n",
        "    rmrt=list(np.where(self.data['brain_area']!=region))[0]\n",
        "    print(f' removing data from {len(rmrt)} neurons not contained in {region} ')\n",
        "    self.data['spks']=np.delete(self.data['spks'],rmrt,axis=0)\n",
        "    neur=len(self.data['spks'])\n",
        "    print(f'neurons remaining in trial {neur}')\n",
        "    self.data['brain_area']=np.delete(self.data['brain_area'],rmrt,axis=0)\n",
        "    self.data['ccf']=np.delete(self.data['ccf'],rmrt,axis=0)\n",
        "    \n",
        "  def FlattenTs(self):\n",
        "    self.data['spks']=np.hstack(self.data['spks'][:])\n",
        "\n",
        "  def removeTrialAvgFR(self):\n",
        "    mFR = self.data['spks'].mean(1)\n",
        "    mFR = np.expand_dims(mFR, 1).repeat(self.data['spks'].shape[1],axis = 1)\n",
        "    print(np.shape(self.data['spks']))\n",
        "    print(np.shape(mFR))\n",
        "    self.data['spks'] = self.data['spks'].astype(float)\n",
        "    self.data['spks'] -= mFR\n",
        "  def permdims(self):\n",
        "    return torch.permute(torch.tensor(self.data['spks']),(2,1,0))\n",
        "\n",
        "  def smoothFR(self, smoothingWidth):# TODO: Smooth the data and save it back to the data structure\n",
        "    return 0\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXUs7BOdEq-a"
      },
      "source": [
        "# function to run all areas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PaVL2Y7-fW"
      },
      "source": [
        "def run_each_region(PA_name,IA_name,ncomp,learning_rate_start,plot_on = False,verbose = False,niter = 400):\n",
        "  nTr = np.argwhere(validtrials) # since the other trials were defaulted to a zero value, only plot the valid trials\n",
        "\n",
        "  ## plot a trial\n",
        "  if plot_on:\n",
        "    plt.figure()\n",
        "    curr_session.plotTrial(nTr[1])\n",
        "    plt.title('All')\n",
        "\n",
        "  PA = copy.deepcopy(curr_session)\n",
        "  ###remove all neurons not in motor cortex\n",
        "  PA.extractROI(PA_name)\n",
        "  ### plot a trial from motor neuron\n",
        "  if plot_on:\n",
        "    plt.figure()\n",
        "    PA.plotTrial(nTr[1])\n",
        "    plt.title('Predicted Area')\n",
        "  ### permute the trials\n",
        "  PAdata = PA.permdims().float().to(device)\n",
        "  PAdata = PAdata[:,validtrials,:]\n",
        "\n",
        "  if IA_name == 'noise':\n",
        "    # generate some negative controls:\n",
        "    IAdata= torch.maximum(torch.randn(PAdata.shape),torch.zeros(PAdata.shape)) # for now say the shape of noise matches the predicted area, I doubt that matters?\n",
        "    if plot_on:\n",
        "      plt.figure()\n",
        "      plt.imshow(IAdata[:,nTr,:].numpy(),cmap = 'gray_r',aspect = 'auto')\n",
        "      plt.title('Random noise')\n",
        "    IAdata = IAdata.float().to(device)\n",
        "  else:\n",
        "    IA = copy.deepcopy(curr_session)\n",
        "    ###remove all neurons not in motor cortex\n",
        "    IA.extractROI(IA_name)\n",
        "    if plot_on:\n",
        "      ### plot a trial from motor neuron\n",
        "      plt.figure()\n",
        "      IA.plotTrial(nTr[1])\n",
        "      plt.title('Input Area')\n",
        "    IAdata = IA.permdims().float().to(device)\n",
        "    IAdata = IAdata[:,validtrials,:]\n",
        "\n",
        "  ##@title get indices for trials (split into ~60%, 30%,10%)\n",
        "  N = PAdata.shape[1]\n",
        "  np.random.seed(42)\n",
        "  ii = torch.randperm(N).tolist()\n",
        "  idx_train = ii[:math.floor(0.6*N)]\n",
        "  idx_val = ii[math.floor(0.6*N):math.floor(0.9*N)]\n",
        "  idx_test = ii[math.floor(0.9*N):]\n",
        "\n",
        "  ##@title split into train, test and validation set\n",
        "  x0 = IAdata\n",
        "  x0_train = IAdata[:,idx_train,:]\n",
        "  x0_val = IAdata[:,idx_val,:]\n",
        "  x0_test = IAdata[:,idx_test,:]\n",
        "\n",
        "  x1 = PAdata\n",
        "  x1_train = PAdata[:,idx_train,:]\n",
        "  x1_val = PAdata[:,idx_val,:]\n",
        "  x1_test = PAdata[:,idx_test,:]\n",
        "\n",
        "  NN1 = PAdata.shape[2]\n",
        "  NN2 = IAdata.shape[2]\n",
        "\n",
        "  class Net_singleinput(nn.Module): # our model\n",
        "    def __init__(self, ncomp, NN2, NN1, bidi=True): # NN2 is input dim, NN1 is output dim\n",
        "      super(Net_singleinput, self).__init__()\n",
        "\n",
        "      # play with some of the options in the RNN!\n",
        "      self.rnn1 = nn.RNN(NN2, ncomp, num_layers = 1, dropout = 0, # PA\n",
        "                        bidirectional = bidi, nonlinearity = 'tanh')\n",
        "\n",
        "      self.fc = nn.Linear(ncomp,NN1)\n",
        "\n",
        "    def forward(self, x0):\n",
        "      y =  self.rnn1(x0)[0] # ncomp IAs\n",
        "\n",
        "      if self.rnn1.bidirectional:\n",
        "        # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
        "        # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
        "        q = (y[:, :, :ncomp] + y[:, :, ncomp:])/2\n",
        "      else:\n",
        "        q = y\n",
        "\n",
        "      # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
        "      # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
        "      z = F.softplus(self.fc(q), 10)\n",
        "  \n",
        "      return z, q\n",
        "\n",
        "  # @title train loop\n",
        "  # you can keep re-running this cell if you think the cost might decrease further\n",
        "\n",
        "  # we define the Poisson log-likelihood loss\n",
        "  def Poisson_loss(lam, spk):\n",
        "    return lam - spk * torch.log(lam)\n",
        "\n",
        "  def train(net,train_input,train_output,val_input,val_output,niter = niter):\n",
        "    set_seed(42)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate_start)\n",
        "    training_cost = []\n",
        "    val_cost = []\n",
        "    for k in range(niter):\n",
        "      ### training\n",
        "      optimizer.zero_grad()\n",
        "      # the network outputs the single-neuron prediction and the latents\n",
        "      z,_= net(train_input)\n",
        "      # our log-likelihood cost\n",
        "      cost = Poisson_loss(z, train_output).mean()\n",
        "      # train the network as usual\n",
        "      cost.backward()\n",
        "      optimizer.step()\n",
        "      training_cost.append(cost.item())\n",
        "\n",
        "      ### test on validation data\n",
        "      z_val,_ = net(val_input)\n",
        "      cost = Poisson_loss(z_val, val_output).mean()\n",
        "      val_cost.append(cost.item())\n",
        "\n",
        "      if (k % 100 == 0)& verbose:\n",
        "        print(f'iteration {k}, cost {cost.item():.4f}')\n",
        "      \n",
        "    return training_cost,val_cost\n",
        "\n",
        "  # @title train model PA->PA only\n",
        "  net_PAPA = Net_singleinput(ncomp, NN1, NN1, bidi = False).to(device)\n",
        "  net_PAPA.fc.bias.data[:] = x1.mean((0,1))\n",
        "  training_cost_PAPA,val_cost_PAPA = train(net_PAPA,x1_train,x1_train,x1_val,x1_val) # train\n",
        "\n",
        "  # @title train model IA->PA only\n",
        "  net_IAPA = Net_singleinput(ncomp, NN2, NN1, bidi = False).to(device)\n",
        "  net_IAPA.fc.bias.data[:] = x1.mean((0,1))\n",
        "  training_cost_IAPA,val_cost_IAPA = train(net_IAPA,x0_train,x1_train,x0_val,x1_val) # train\n",
        "\n",
        "  # get latents\n",
        "  z_PAPA,y_PAPA= net_PAPA(x1_train)\n",
        "  z_IAPA,y_IAPA= net_IAPA(x0_train)\n",
        "\n",
        "  #@title plot the training side-by-side\n",
        "  if plot_on:\n",
        "    plt.figure()\n",
        "    plt.plot(training_cost_PAPA,'b')\n",
        "    plt.plot(training_cost_IAPA,'b',linestyle = '--')\n",
        "\n",
        "    plt.plot(val_cost_PAPA,'r')\n",
        "    plt.plot(val_cost_IAPA,'r',linestyle = '--')\n",
        "\n",
        "    plt.legend(['training cost (PAPA)','training cost (IAPA)','validation cost(PAPA)',\n",
        "                'validation cost (IAPA)'])\n",
        "    plt.title('Training cost over epochs')\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('epochs')\n",
        "\n",
        "    # see if the latents are correlated?\n",
        "    plt.figure()\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(y_PAPA[:,0,:].detach().cpu().numpy())\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(y_IAPA[:,0,:].detach().cpu().numpy())\n",
        "\n",
        "  if verbose:\n",
        "    print(F.cosine_similarity(z_PAPA.flatten(start_dim = 0,end_dim = 1).T,z_IAPA.flatten(start_dim = 0,end_dim = 1).T).mean())\n",
        "    print(F.cosine_similarity(z_PAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).mean())\n",
        "    print(F.cosine_similarity(z_IAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).mean())\n",
        "\n",
        "  diff_cosine_similarity = torch.subtract(F.cosine_similarity(z_PAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).mean(),F.cosine_similarity(z_IAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).mean())\n",
        "  diff_cosine_similarity = diff_cosine_similarity.detach().cpu().tolist()\n",
        "\n",
        "  if plot_on:\n",
        "    plt.figure()\n",
        "    plt.hist(F.cosine_similarity(z_PAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).detach().cpu().numpy())\n",
        "    plt.hist(F.cosine_similarity(z_IAPA.flatten(start_dim = 0,end_dim = 1).T,x1_train.flatten(start_dim = 0,end_dim = 1).T).detach().cpu().numpy())\n",
        "    plt.legend(('PAPA','IAPA'))\n",
        "    plt.title('cosine_similarity by neuron')\n",
        "\n",
        "  def regress_tensor(X,y):\n",
        "    X = X.detach().cpu().numpy()\n",
        "    y = y.flatten().detach().cpu().numpy().reshape(-1,1)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    r_sq = model.score(X, y)\n",
        "    if verbose:\n",
        "      print('coefficient of determination:', r_sq)\n",
        "    return r_sq\n",
        "\n",
        "  rsqmat = []\n",
        "  for i in range(ncomp):\n",
        "    rsqmat.append(regress_tensor(y_IAPA.flatten(start_dim = 0,end_dim = 1),y_PAPA[:,:,i].reshape(-1,1)))\n",
        "\n",
        "  Avg_rsq = sum(rsqmat)/len(rsqmat)\n",
        "  max_rsq = max(rsqmat)\n",
        "  if verbose:\n",
        "    print('Average Rsq for predicting the %i latents in IAPA from a linear combination of %i latents in PAPA is %2.3f'%(ncomp,ncomp,Avg_rsq))\n",
        "    print('Max Rsq for predicting the %i latents in IAPA from a linear combination of %i latents in PAPA is %2.3f'%(ncomp,ncomp,max_rsq))\n",
        "\n",
        "\n",
        "  return diff_cosine_similarity,rsqmat"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwRutpqBuRpn"
      },
      "source": [
        "# select session and area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au2DjIm60Puf",
        "outputId": "e8617b35-edc4-4683-ccd0-866cf429b681"
      },
      "source": [
        "# set the sessions\n",
        "session_num = 30\n",
        "curr_session=SteinmetzSession(alldat[session_num])\n",
        "# some preprocessing\n",
        "validtrials = curr_session.realign_data_to_movement(500) # get 500 ms from movement time, \n",
        "# cannot get realign and binning to work the same time =[\n",
        "  # print areas\n",
        "areas = curr_session.get_areas()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spikes aligned to movement, returning validtrials\n",
            "{'ORB', 'CA3', 'POST', 'MOs', 'SCm', 'TH', 'SNr', 'OLF'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzJ5DA9pEIBU",
        "outputId": "323037b4-5776-444c-f48c-539080a1a19b"
      },
      "source": [
        "# CHANGE ME\n",
        "# Set input/hyperparameters here:\n",
        "ncomp = 10\n",
        "learning_rate_start = 0.005\n",
        "\n",
        "# set areas\n",
        "PA_name = 'MOs' # predicted area\n",
        "IA_name = 'noise'\n",
        "diff_cosine_similarity,rsqmat = run_each_region(PA_name,IA_name,ncomp,learning_rate_start,plot_on= True,verbose = True)\n",
        "\n",
        "\n",
        "# all_other_areas = ['noise']\n",
        "# all_other_areas = all_other_areas+list(areas-set([PA_name]))\n",
        "\n",
        "# print(all_other_areas)\n",
        "\n",
        "# counter = 0\n",
        "# for IA_name in all_other_areas:\n",
        "#   print(IA_name)\n",
        "#   diff_cosine_similarity,rsqmat = run_each_region(PA_name,IA_name,ncomp,learning_rate_start)\n",
        "\n",
        "#   if counter == 0:\n",
        "#     allrsq = np.array(rsqmat)\n",
        "#     cos_sim_mat = np.array(diff_cosine_similarity)\n",
        "#   else:\n",
        "#     allrsq = np.vstack((allrsq,np.array(rsqmat)))\n",
        "#     cos_sim_mat = np.vstack((cos_sim_mat,np.array(diff_cosine_similarity)))\n",
        "#   counter +=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " removing data from 696 neurons not contained in MOs \n",
            "neurons remaining in trial 281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHf4F3IVHYaX"
      },
      "source": [
        "# summary = {'output area':PA_name,'input area':all_other_areas,...\n",
        "#            'cosine_similarity_difference':cos_sim_mat,...\n",
        "#            'all rsq':allrsq};"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbyP-Xm1AsgI"
      },
      "source": [
        "# import json\n",
        "# summary_file = open(\"data.json\", \"w\")\n",
        "# json.dump(summary, summary_file)\n",
        "# summary_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FC5X8lZ7r9I"
      },
      "source": [
        "# plt.figure()\n",
        "# plt.hist(rsqmat)\n",
        "# plt.ylabel('number of components');\n",
        "# plt.xlabel('Rsq')\n",
        "# plt.title('Rsq for predicting Predicted Area latents from Input Area latents')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}